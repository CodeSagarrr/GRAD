{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e914ca2",
   "metadata": {},
   "source": [
    "## RAG basics (Retrieval Augmented Generation) :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2063f1d3",
   "metadata": {},
   "source": [
    "* RAG ek technique hai jisme LLM ko sirf apni training memory par depend nahi rehna padta balki external documents se relevant information retrieve karke answer generate karta hai.\n",
    "\n",
    "* Isme do main steps hote hain retrieval aur generation. Pehle system relevant data dhundhta hai phir LLM us data ko use karke final response banata hai.\n",
    "\n",
    "* RAG hallucination problem ko kam karta hai kyunki model guess nahi karta balki actual documents se answer deta hai.\n",
    "\n",
    "* Ye approach dynamic knowledge ke liye best hai jaise PDFs, notes, company data, policies jo model ke training ke baad aaye hote hain.\n",
    "\n",
    "* LLMs static hote hain lekin real world data dynamic hota hai. RAG is gap ko fill karta hai.\n",
    "\n",
    "* Ye enterprise AI systems ka base hai jaha private data ko securely use karna hota hai.\n",
    "\n",
    "* RAG accuracy aur trust dono improve karta inspired by search + generation model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19eae0a8",
   "metadata": {},
   "source": [
    "## Embeddings (RAG Context) :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e499d13",
   "metadata": {},
   "source": [
    "* Embeddings text ko dense numerical vectors me convert karte hain jisme meaning store hota hai.\n",
    "\n",
    "* Similar meaning wale text ke vectors close hote hain aur different meaning wale door.\n",
    "\n",
    "* RAG me embeddings ka use documents aur query dono ko same vector space me lane ke liye hota hai.\n",
    "\n",
    "* Ye semantic search possible banata hai jaha exact word match nahi balki meaning match hota hai.\n",
    "\n",
    "* Embeddings bina keywords ke relevant content dhundhne me madad karti hain.\n",
    "\n",
    "* Large text data ko efficiently compare karna possible hota hai.\n",
    "\n",
    "* Ye RAG ke retrieval step ka backbone hota hai."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9851a7a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.014138972386717796, -0.024635283276438713, 0.05002330616116524, -0.11973728984594345, 0.008941663429141045, -0.03222166746854782, -0.051894813776016235, 0.062491536140441895, 0.025787075981497765, -0.021769948303699493, -0.02081720158457756, -0.005019721109420061, 0.011507866904139519, -0.0011709253303706646, 0.07824187725782394, 0.035470061004161835, 0.008089656010270119, 0.08329253643751144, 0.04782746732234955, -0.07897520065307617, -0.021960780024528503, -0.04138180613517761, 0.04501473158597946, 0.05675424262881279, 0.06118106096982956, -0.07703030854463577, 0.043954066932201385, 0.03707760572433472, 0.0894288718700409, -0.02595287747681141, 0.008475967682898045, 0.1328008770942688, -0.05419498682022095, 0.0015967212384566665, -0.09040915220975876, 0.09495869278907776, 0.004634810145944357, -0.024181600660085678, -0.03745850548148155, -0.0740288719534874, -0.040495630353689194, 0.010981051251292229, 0.06296328455209732, -0.027635274454951286, 0.029761357232928276, -0.0454586036503315, 0.018843553960323334, 0.01783793233335018, -0.14818131923675537, 0.012679489329457283, 0.029110021889209747, -0.07225629687309265, 0.0011746467789635062, -0.02716830000281334, -0.021849052980542183, 0.0054198624566197395, 0.006385869346559048, 0.05524269863963127, 0.0026358929462730885, -0.020519305020570755, -0.004216779489070177, 0.026813937351107597, -0.04991834983229637, 0.04396970570087433, 0.020981909707188606, 0.06644520908594131, 0.042940933257341385, 0.13371941447257996, -0.028152531012892723, 0.0026606577448546886, 0.011952165514230728, -0.10826916247606277, 0.008869352750480175, 0.032581720501184464, -0.08337967842817307, -0.026086248457431793, -0.019738253206014633, -0.011838367208838463, 0.04696584865450859, -0.06268009543418884, 0.057767342776060104, 0.12726488709449768, -0.011956649832427502, 0.042208295315504074, -0.022889142856001854, 0.013863226398825645, 0.030502334237098694, 0.04215062037110329, 0.04631994292140007, 0.020854327827692032, 0.0862811878323555, -0.05480499938130379, -0.005117601715028286, -0.007590378634631634, 0.0015773088671267033, 0.0011495152721181512, 0.0338100865483284, 0.03631630539894104, -0.03198240324854851, 0.041641898453235626, 0.0031337912660092115, 7.435143925249577e-05, 0.05943313241004944, -0.04594684764742851, -0.055111464112997055, 0.022114142775535583, -0.003162105567753315, -0.003999430686235428, 0.059882838279008865, -0.020672883838415146, -8.477399387629703e-05, 0.024146150797605515, -0.033644430339336395, -0.020947851240634918, -0.07121293246746063, -0.02978198044002056, 0.033921945840120316, -0.07618017494678497, 0.024195054545998573, 0.07555823773145676, -0.046929243952035904, -0.03912787884473801, -0.038102149963378906, -0.0347437746822834, 0.0023948969319462776, -0.01161162182688713, -0.026186082512140274, -6.056594019508344e-35, 0.08751315623521805, -0.02715536579489708, -0.031240662559866905, 0.041977085173130035, 0.0940370187163353, -0.08032100647687912, 0.08367069065570831, 0.026422129943966866, -0.09326087683439255, -0.09920918941497803, -0.013245923444628716, -0.00026732374681159854, -0.05306127294898033, 0.021577075123786926, 0.06822165101766586, -0.04859648272395134, -0.00795161072164774, -0.019211186096072197, 0.013939951546490192, -0.015765376389026642, -0.0056262086145579815, -0.029158463701605797, 0.05889955908060074, -0.06471278518438339, 0.07523319870233536, 0.0591762438416481, 0.14512136578559875, -0.015132734552025795, 0.03140858933329582, 0.03637249395251274, -0.03227514401078224, -0.04863091930747032, -0.020941613242030144, 0.06040925160050392, 0.009513838216662407, 0.045967262238264084, -0.08816172927618027, -0.04470831900835037, 0.05160938948392868, -0.04836824908852577, 0.049903493374586105, 0.04885222762823105, -0.0037594924215227365, -0.035827651619911194, -0.003982124850153923, 0.028454814106225967, 0.032112278044223785, -0.0335216298699379, 0.016627000644803047, -0.006436346564441919, 0.06877905875444412, 0.052785724401474, -0.08910011500120163, 0.043477825820446014, 0.022266246378421783, 0.0034630494192242622, -0.042620301246643066, -0.05635493993759155, -0.05377069115638733, 0.02659369632601738, -0.07413554936647415, -0.010035432875156403, 0.007318148389458656, 0.06901929527521133, 0.028732089325785637, 0.02651245892047882, -0.08754870295524597, -0.028971455991268158, 0.013061580248177052, -0.0356484018266201, -0.00493239751085639, -0.0804906114935875, 0.016459453850984573, 0.09367718547582626, -0.04069460928440094, 0.014616405591368675, 0.012622689828276634, -0.023842934519052505, 0.03003034181892872, 0.005965780466794968, 0.005039485637098551, -0.00026352202985435724, -0.04478174075484276, 0.041428882628679276, 0.022822780534625053, 0.015745315700769424, -0.0008186960476450622, -0.05459393188357353, 0.0049429466016590595, 0.05659252777695656, 0.005424083210527897, -0.0483577698469162, 0.052502959966659546, 0.08394909650087357, -0.06396423280239105, -4.608979614132909e-35, -0.09067708998918533, -0.07906791567802429, 0.01531735435128212, 0.04611567407846451, -0.040962181985378265, -0.015303670428693295, -0.03059663437306881, 0.05982425808906555, -0.029132241383194923, 0.027502933517098427, -0.039050955325365067, -0.015599759295582771, 0.030898144468665123, 0.0793604850769043, 0.005117207299917936, -0.060848504304885864, 0.05081554129719734, -0.00874551571905613, 0.07511594891548157, 0.026781808584928513, -0.03404996171593666, 0.07797128707170486, -0.038783419877290726, 0.019326189532876015, -0.023739119991660118, -0.01572263054549694, -0.07098320871591568, -0.00673488387838006, 0.004052014090120792, 0.0441148579120636, 0.05967634916305542, -0.05156800150871277, -0.07585664838552475, -0.03398153930902481, -0.08418788015842438, -0.020035643130540848, 0.022062266245484352, 0.06291695684194565, -0.008061029948294163, -0.03994215279817581, 0.07404374331235886, -0.04706718027591705, -0.022699136286973953, 0.01598874107003212, -0.053685225546360016, 0.023732168599963188, -0.10062143951654434, -0.025975899770855904, 0.08239224553108215, -0.0901360884308815, 0.11610064655542374, -0.02965724840760231, 0.10635185241699219, -0.12691408395767212, -0.054086558520793915, -0.0082508884370327, 0.06249941512942314, -0.050907451659440994, -0.043795786798000336, -0.05032847821712494, -0.03691285103559494, -0.009662745520472527, 0.038012780249118805, -0.11192315071821213, 0.019237656146287918, 0.016673889011144638, -0.02825647033751011, 0.05070162191987038, -0.04648922011256218, -0.045435644686222076, 0.13451993465423584, -0.012328336015343666, -0.07923363149166107, 0.05083179473876953, -0.03723694756627083, -0.03761214390397072, -0.004470075014978647, -0.06762956827878952, 0.024451080709695816, -0.05889064073562622, 0.0460490807890892, 0.044553473591804504, -0.012966359034180641, -0.00405689375475049, 0.02462530881166458, -0.006922912783920765, 0.033669035881757736, 0.052033018320798874, 0.020242784172296524, -0.00642872741445899, -0.008450474590063095, 0.1175142228603363, -0.041038546711206436, 0.06786341220140457, 0.0036036826204508543, -1.498304946778717e-08, 0.006301174405962229, -0.12087281048297882, -0.07130758464336395, 0.010320090688765049, -0.10744132846593857, -0.029905211180448532, 0.05306581035256386, 0.07441645115613937, 0.02449038252234459, 0.015422042459249496, 0.013907096348702908, 0.03974919021129608, -0.14822812378406525, 0.04472919553518295, 0.01366510521620512, 0.02507893182337284, 0.05018634721636772, 0.11915024369955063, -0.09650453180074692, -0.025603583082556725, 0.03169144317507744, 0.08871962875127792, 0.020083770155906677, 0.01008144672960043, 0.03712114691734314, -0.013301032595336437, 0.07239396870136261, 0.07311876863241196, 0.05306767672300339, -0.009948307648301125, -0.018089132383465767, 0.006129492539912462, -0.04865866154432297, 0.04654378816485405, -0.008945554494857788, 0.016061991453170776, -0.07455110549926758, -0.02440456859767437, 0.1033744364976883, -0.0007870752015151083, 0.031402092427015305, -0.0013902285136282444, 0.03678503632545471, 0.05326874554157257, -0.055635806173086166, -0.08849658817052841, -0.08011741191148758, -0.032506734132766724, 0.011410490609705448, -0.011091471649706364, -0.02313901297748089, -0.023655356839299202, -0.004995751194655895, -0.010787064209580421, 0.0355985090136528, 0.046248458325862885, -0.007653958164155483, -0.0013808223884552717, 0.06773249804973602, -0.021166855469346046, 0.038826338946819305, -0.03460873290896416, 0.05255088955163956, 0.019298812374472618]\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# Embedding model load\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    ")\n",
    "\n",
    "# Sample text\n",
    "text = \"LangChain helps build LLM applications\"\n",
    "\n",
    "# Text ko vector me convert\n",
    "vector = embeddings.embed_query(text)\n",
    "\n",
    "print(vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ec4766",
   "metadata": {},
   "source": [
    "## Vector Stores :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b498cb6b",
   "metadata": {},
   "source": [
    "* Vector store ek database hota hai jaha embeddings store ki jaati hain.\n",
    "\n",
    "* Ye similarity search ke liye optimized hota hai jisse fast retrieval possible hota hai.\n",
    "\n",
    "* Vector store query ke embedding ko stored embeddings se compare karta hai.\n",
    "\n",
    "* Popular vector stores FAISS, Chroma, Pinecone hote hain.\n",
    "\n",
    "* why in AI/ML :\n",
    "\n",
    "    - Simple list comparison slow hota hai jab data bada ho jata hai.\n",
    "\n",
    "    - Vector store millions of embeddings ko efficiently handle karta hai.\n",
    "\n",
    "    - Ye real time RAG systems ke liye critical hota hai."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9169cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "\n",
    "texts = [\n",
    "    \"LangChain is a framework for LLM apps\",\n",
    "    \"RAG improves LLM accuracy\",\n",
    "    \"Embeddings capture text meaning\"\n",
    "]\n",
    "\n",
    "# Vector store create\n",
    "vector_store = FAISS.from_texts(texts , embeddings)\n",
    "\n",
    "# Similar search\n",
    "results = vector_store.similarity_search(\"What is RAG?\")\n",
    "\n",
    "print(results[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db91320",
   "metadata": {},
   "source": [
    "## Document Loaders :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c0bc53",
   "metadata": {},
   "source": [
    "* Document loaders raw files ko readable text me convert karte hain.\n",
    "\n",
    "* Ye PDFs, TXT, DOCX, HTML jaise formats support karte hain.\n",
    "\n",
    "* Loader text ko chunks me todta hai taaki embeddings efficient bane.\n",
    "\n",
    "* Ye RAG pipeline ka entry point hota hai.\n",
    "\n",
    "* Real world data files ke form me hota hai, direct text nahi.\n",
    "\n",
    "* Large documents ko manageable pieces me todna zaroori hota hai.\n",
    "\n",
    "* Chunking se context loss kam hota hai."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a88d654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello I am sagar , and i am testing how Text loader work in langchain\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "loader = TextLoader(\"test.txt\") # Add txt file\n",
    "docs = loader.load()\n",
    "# file ka content text form me load hua\n",
    "\n",
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d53c285",
   "metadata": {},
   "source": [
    "## Simple RAG Pipeline :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dcc20b7",
   "metadata": {},
   "source": [
    "* Simple RAG pipeline me document load hota hai phir embeddings banti hain.\n",
    "\n",
    "* Embeddings vector store me save hoti hain.\n",
    "\n",
    "* User query ko embedding me convert karke similar documents retrieve hote hain.\n",
    "\n",
    "* Retrieved text ko LLM ke prompt me add karke final answer generate hota hai.\n",
    "\n",
    "* Ye end to end intelligent system banata hai.\n",
    "\n",
    "* Private aur updated data ke sath LLM use karna possible hota hai.\n",
    "\n",
    "* Ye real applications jaise chatbot, knowledge base, QnA systems ka base hai."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e1b64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.llms import OpenAI\n",
    "from langchain_community.chains import RetrievalQA\n",
    "\n",
    "# Step 1: Load documents\n",
    "loader = TextLoader(\"test.txt\")\n",
    "documents = loader.load()\n",
    "\n",
    "# Step 2: Create embeddings\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    ")\n",
    "\n",
    "# Step 3: Vector store\n",
    "vector_store = FAISS.from_documents(documents, embeddings)\n",
    "\n",
    "# Step 4: Load LLM\n",
    "llm = OpenAI(temperature=0.2)\n",
    "\n",
    "# Step 5: RAG chain\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=vector_store.as_retriever()\n",
    ")\n",
    "\n",
    "# Step 6: Ask question\n",
    "response = qa_chain.run(\"Explain RAG in simple words\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabd9750",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
